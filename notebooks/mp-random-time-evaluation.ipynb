{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model A\n",
    "\n",
    "Model A is trained using random time points for each patient. We first train this model, then evaluate it on a separate dataset with data extracted at fixed lead times from mortality for the patients who died in-hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties # for unicode fonts\n",
    "import psycopg2\n",
    "import sys\n",
    "import datetime as dt\n",
    "import mp_utils as mp\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# used to print out pretty pandas dataframes\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# used to impute mean for data and standardize for computational stability\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression is our favourite model ever\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV # l2 regularized regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# used to create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# gradient boosting - must download package https://github.com/dmlc/xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "from eli5 import show_weights\n",
    "\n",
    "# default colours for prettier plots\n",
    "col = [[0.9047, 0.1918, 0.1988],\n",
    "    [0.2941, 0.5447, 0.7494],\n",
    "    [0.3718, 0.7176, 0.3612],\n",
    "    [1.0000, 0.5482, 0.1000],\n",
    "    [0.4550, 0.4946, 0.4722],\n",
    "    [0.6859, 0.4035, 0.2412],\n",
    "    [0.9718, 0.5553, 0.7741],\n",
    "    [0.5313, 0.3359, 0.6523]];\n",
    "marker = ['v','o','d','^','s','o','+']\n",
    "ls = ['-','-','-','-','-','s','--','--']\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# below config used on pc70\n",
    "sqluser = 'alistairewj'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "query_schema = 'SET search_path to public,' + schema_name + ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exclusion criteria:\n",
    "#   - less than 16 years old\n",
    "#   - stayed in the ICU less than 4 hours\n",
    "#   - never have any chartevents data (i.e. likely administrative error)\n",
    "query = query_schema + \\\n",
    "\"\"\"\n",
    "select \n",
    "    subject_id, hadm_id, icustay_id\n",
    "from mp_cohort\n",
    "where excluded = 0\n",
    "\"\"\"\n",
    "co = pd.read_sql_query(query,con)\n",
    "\n",
    "# extract static vars into a separate dataframe\n",
    "df_static = pd.read_sql_query(query_schema + 'select * from mp_static_data', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ~5 million rows containing data from errbody\n",
    "# this takes a little bit of time to load into memory (~2 minutes)\n",
    "\n",
    "# %%time results\n",
    "# CPU times: user 42.8 s, sys: 1min 3s, total: 1min 46s\n",
    "# Wall time: 2min 7s\n",
    "\n",
    "df = pd.read_sql_query(query_schema + 'select * from mp_data', con)\n",
    "df.drop('subject_id',axis=1,inplace=True)\n",
    "df.drop('hadm_id',axis=1,inplace=True)\n",
    "df.sort_values(['icustay_id','hr'],axis=0,ascending=True,inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get death information\n",
    "df_death = pd.read_sql_query(query_schema + \"\"\"\n",
    "select \n",
    "co.subject_id, co.hadm_id, co.icustay_id\n",
    ", ROW_NUMBER() over (PARTITION BY co.subject_id ORDER BY co.intime) as icustay_num\n",
    ", ceil(extract(epoch from (co.outtime - co.intime))/60.0/60.0) as dischtime_hours\n",
    ", ceil(extract(epoch from (adm.deathtime - co.intime))/60.0/60.0) as deathtime_hours\n",
    ", case when adm.deathtime is null then 0 else 1 end as death\n",
    "from mp_cohort co\n",
    "inner join admissions adm\n",
    "on co.hadm_id = adm.hadm_id\n",
    "where co.excluded = 0\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get censoring information\n",
    "df_censor = pd.read_sql_query(query_schema + \"\"\"\n",
    "select co.icustay_id, min(cs.charttime) as censortime\n",
    ", ceil(extract(epoch from min(cs.charttime-co.intime) )/60.0/60.0) as censortime_hours\n",
    "from mp_cohort co \n",
    "inner join mp_code_status cs\n",
    "on co.icustay_id = cs.icustay_id\n",
    "where cmo+dnr+dni+dncpr+cmo_notes>0\n",
    "and co.excluded = 0\n",
    "group by co.icustay_id\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Ensure we do not pull data if patient is DNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of why this may be necessary\n",
    "mp.plot_vitals(df, iid=200019, df_death=df_death, df_censor=df_censor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5 # number of folds\n",
    "var_min, var_max, var_first, var_last, var_sum, var_first_early, var_last_early, var_static = mp.vars_of_interest()\n",
    "\n",
    "df_tmp=df_death.copy().merge(df_censor, how='left', left_on='icustay_id', right_on='icustay_id')\n",
    "time_dict = mp.generate_times(df_tmp, T=2, seed=111, censor=True)\n",
    "df_data = mp.get_design_matrix(df, time_dict, W=24, W_extra=24)\n",
    "\n",
    "# remove icustay_ids if they were censored (made DNR) before icu admission, or close enough to that\n",
    "idx = df_censor.loc[df_censor['censortime_hours']<=0, 'icustay_id']\n",
    "print('Removed {} icustay_id as they were censored on/before ICU admission.'.format((idx.shape[0])))\n",
    "df_data.drop(idx, axis=0, inplace=True)\n",
    "\n",
    "# get unique subject_id\n",
    "sid = np.sort(np.unique(df_death['subject_id'].values))\n",
    "\n",
    "# assign k-fold\n",
    "idxK_sid = np.random.permutation(sid.shape[0])\n",
    "idxK_sid = np.mod(idxK_sid,K)\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(df_death.set_index('icustay_id')[['death']], left_index=True, right_index=True)\n",
    "\n",
    "# generate K-fold indices\n",
    "X = X.merge(df_death.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "\n",
    "# drop the subject_id column\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "# pick a subset of columns\n",
    "col_keep = ['heartrate_last', 'sysbp_last', 'diasbp_last', 'meanbp_last', 'resprate_last', 'tempc_last', 'spo2_last',\n",
    "           'creatinine_last', 'bilirubin_last', 'platelet_last', 'hemoglobin_last',\n",
    "           'death']\n",
    "X = X[col_keep]\n",
    "\n",
    "X_header = X.columns.values\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = {'xgb': xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05),\n",
    "          'lasso': LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000),\n",
    "          'logreg': LogisticRegression(fit_intercept=True),\n",
    "          'rf': RandomForestClassifier()\n",
    "         }\n",
    "\n",
    "\n",
    "# create k-fold indices\n",
    "K = 5 # number of folds\n",
    "idxK = np.random.permutation(X.shape[0])\n",
    "idxK = np.mod(idxK,K)\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = sklearn.base.clone(estimator).fit(X[idxK != k, :], y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "        \n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train just an LR on all the data and get the coefficients\n",
    "X2 = X.copy()\n",
    "\n",
    "mu = list()\n",
    "sig = list()\n",
    "for i in range(X2.shape[1]):\n",
    "    mu.append( np.mean(X2[~np.isnan(X2[:,i]),i]) )\n",
    "    sig.append( np.std(X2[~np.isnan(X2[:,i]),i]) )\n",
    "    \n",
    "    X2[np.isnan(X2[:,i]),i] = mu[i]\n",
    "    \n",
    "    \n",
    "# fit LR on this data\n",
    "mdl =  LogisticRegression(fit_intercept=True)\n",
    "mdl = mdl.fit(X2, y)\n",
    "print('{:0.5f}\\tIntercept'.format(mdl.intercept_[0]))\n",
    "for i, x in enumerate(X_header):\n",
    "    if x=='death':\n",
    "        continue\n",
    "    if mdl.coef_[0][i]>0:\n",
    "        print('+',end='')\n",
    "    print('{:0.5f} * {}'.format(mdl.coef_[0][i], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, x in enumerate(X_header):\n",
    "    if x=='death':\n",
    "        continue\n",
    "    print('{:4.2f}\\t{}'.format(mu[i], x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sanity check - plot age to see if header/data lined up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,8])\n",
    "idx = [i for i, j in enumerate(X_header) if j == 'age'][0]\n",
    "idxNotNull = ~np.isnan(X[:,idx])\n",
    "plt.hist(X[idxNotNull,idx], bins=np.linspace(0,100,101))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# average AUROC + min/max\n",
    "for mdl in models:\n",
    "    curr_score = np.asarray(results_val[mdl],dtype=float)\n",
    "    print('{}\\t{:0.3f} [{:0.3f}, {:0.3f}]'.format(mdl, np.mean(curr_score), np.min(curr_score), np.max(curr_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mp.plot_model_results(results_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a single patient's trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new XGB model with 75% of the data as training\n",
    "all_xs, all_ys = shuffle(X, y, random_state=0)\n",
    "train_xs, valid_xs, train_ys, valid_ys = train_test_split(\n",
    "    all_xs, all_ys, test_size=0.25, random_state=0)\n",
    "\n",
    "clf = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05, missing=np.nan)\n",
    "\n",
    "clf = clf.fit(train_xs, train_ys)\n",
    "\n",
    "# pull out the model\n",
    "clf = mdl_base['xgb'][0].get_params()['steps'][0][1]\n",
    "\n",
    "# print weights\n",
    "show_weights(clf, feature_names=X_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# broken code due to xgboost not handling small data well\n",
    "\n",
    "```python\n",
    "from eli5 import show_prediction\n",
    "reload(mp)\n",
    "\n",
    "iid = 200019\n",
    "mdl='xgb'\n",
    "\n",
    "X_pt = mp.get_data_at_time(df, df_static, iid, hour=25)\n",
    "# reshape it to be 2 dimensional\n",
    "X_pt = np.reshape(X_pt, [1,X_pt.shape[1]])\n",
    "#X_pt_df = pd.DataFrame(X_pt, columns=X_header, dtype=float)\n",
    "show_prediction(clf, X_pt, feature_names=X_header, show_feature_values=True)\n",
    "#X_pt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iid = 200019\n",
    "mdl='xgb'\n",
    "\n",
    "pred_all = None\n",
    "for k in range(K):\n",
    "    # get patient time/predictions\n",
    "    curr_mdl = mdl_val[mdl][k]\n",
    "    t, pred = mp.get_predictions(df, df_static, curr_mdl, iid)\n",
    "    \n",
    "    if pred_all is None:\n",
    "        pred_all = pred\n",
    "    else:\n",
    "        pred_all = np.column_stack([pred_all, pred])\n",
    "        \n",
    "    #plt.plot(t, pred, color=col[k],\n",
    "    #        markersize=10, linewidth=2, linestyle='-',\n",
    "    #        label=mdl + '{}'.format(k))\n",
    "    \n",
    "pred_top = np.max(pred_all,axis=1)\n",
    "pred_bot = np.min(pred_all,axis=1)\n",
    "pred_mean = np.mean(pred_all,axis=1)\n",
    "fig, ax = plt.subplots(1,1,figsize=[12,8])\n",
    "ax.plot(t, pred_mean, color=col[0],\n",
    "        markersize=10, linewidth=2, linestyle='-',\n",
    "        label='Average prediction')\n",
    "ax.fill_between(t, pred_bot, pred_top, facecolor=col[0],\n",
    "                alpha=0.5, linewidth=0, interpolate=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model before death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates datasets in X_all for evaluation\n",
    "\n",
    "# experiment elements contain a list: [seed, W (window size), T_to_death]\n",
    "experiments = OrderedDict([['base', [473010,8,None]],\n",
    "               ['24hr', [585794,24,None]],\n",
    "               ['Td=00', [724311,8,0]],\n",
    "               ['Td=04', [952227,8,4]],\n",
    "               ['Td=08', [721297,8,8]],\n",
    "               ['Td=16', [968879,8,16]],\n",
    "               ['Td=24', [608972,8,24]],\n",
    "               ['24hr Td=00', [34741,24,0]],\n",
    "               ['24hr Td=04', [34319,24,4]],\n",
    "               ['24hr Td=08', [95467,24,8]],\n",
    "               ['24hr Td=16', [85349,24,16]],\n",
    "               ['24hr Td=24', [89642,24,24]]\n",
    "                          ])\n",
    "\n",
    "# fuzzyness to allow deathtime to be a little bit after discharge time\n",
    "death_epsilon=2\n",
    "X_all = dict()\n",
    "y_all = dict()\n",
    "iid_all = dict()\n",
    "pred_all = dict()\n",
    "time_all = dict()\n",
    "X_header_all = dict()\n",
    "\n",
    "for e in experiments:\n",
    "    params = experiments[e]\n",
    "    time_all[e] = mp.generate_times_before_death(df_death, seed=params[0], T=2, T_to_death=params[2])\n",
    "    df_data = mp.get_design_matrix(df, time_all[e], W=params[1], W_extra=24)\n",
    "    \n",
    "    # load the data into a numpy array\n",
    "        \n",
    "    # Add in static vars from df_static\n",
    "    X = df_data.merge(df_static.set_index('icustay_id')[var_static],\n",
    "                      how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    \n",
    "    if params[2] is not None:\n",
    "        df_tmp = df_death[['icustay_id','death','dischtime_hours', 'deathtime_hours']].copy()\n",
    "        df_tmp['death_in_icu'] = (df_tmp['deathtime_hours']<=(df_tmp['dischtime_hours']+params[2]+death_epsilon)).astype(float)\n",
    "        X = X.merge(df_tmp[['icustay_id','death_in_icu']].set_index('icustay_id'),\n",
    "                          left_index=True, right_index=True)\n",
    "    else:\n",
    "        X = X.merge(df_death[['icustay_id','death']].set_index('icustay_id'),\n",
    "                          left_index=True, right_index=True)\n",
    "\n",
    "    iid_all[e] = X.index.values\n",
    "    X = X.values\n",
    "    y_all[e] = X[:,-1]\n",
    "    X_all[e] = X[:,0:-1]\n",
    "    \n",
    "    X_header_all[e] = var_static + df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the models on various datasets\n",
    "K = 5 # number of folds\n",
    "results_all = dict()\n",
    "mdl_base = dict()\n",
    "base_exp = 'base'\n",
    "\n",
    "# train the base model\n",
    "e = base_exp\n",
    "\n",
    "# get unique subject_id\n",
    "sid = np.sort(np.unique(df_death['subject_id'].values))\n",
    "\n",
    "# assign k-fold\n",
    "idxK_sid = np.random.permutation(sid.shape[0])\n",
    "idxK_sid = np.mod(idxK_sid,K)\n",
    "\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, df_death['subject_id'].values)\n",
    "\n",
    "# use these indices to map the k-fold integers\n",
    "idxK_all = idxK_sid[idxMap]\n",
    "\n",
    "# get the data for the dataset which the model is developed on\n",
    "X = X_all[e]\n",
    "y = y_all[e]\n",
    "iid_curr = iid_all[e]\n",
    "\n",
    "# map the k-fold indices from all IID to the subset included in this data\n",
    "iid = df_death['icustay_id'].values\n",
    "idxMap = np.nonzero(np.in1d(iid,iid_curr))[0]\n",
    "idxK = idxK_all[idxMap]\n",
    "\n",
    "results_all[e] = dict()\n",
    "\n",
    "\n",
    "idxMap = np.nonzero(np.in1d(iid,iid_curr))[0]\n",
    "\n",
    "for mdl in models:\n",
    "    # train the model for the fixed dataset\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    \n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])])\n",
    "    print('Training 5-fold model for application to various datasets...'.format(K))\n",
    "    \n",
    "    results_all[e][mdl] = list()\n",
    "    mdl_base[mdl] = list()\n",
    "    \n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = sklearn.base.clone(estimator).fit(X[idxK != k, :], y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_all[e][mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_base[mdl].append(curr_mdl)\n",
    "\n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "\n",
    "    # apply the trained model to each dataset in experiments\n",
    "    for e in experiments:\n",
    "        if e == base_exp:\n",
    "            continue\n",
    "            \n",
    "        if e not in results_all:\n",
    "            results_all[e] = dict()\n",
    "        results_all[e][mdl] = list()\n",
    "\n",
    "        X = X_all[e]\n",
    "        y = y_all[e]\n",
    "        iid_curr = iid_all[e]\n",
    "        \n",
    "        # map the k-fold indices from all IID to the subset included in this data\n",
    "        idxMap = np.nonzero(np.in1d(iid,iid_curr))[0]\n",
    "        idxK = idxK_all[idxMap]\n",
    "        \n",
    "        \n",
    "        if mdl == 'xgb':\n",
    "            # no pre-processing of data necessary for xgb\n",
    "            estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "        else:\n",
    "            estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                              strategy=\"mean\",\n",
    "                                              axis=0)),\n",
    "                          (\"scaler\", StandardScaler()),\n",
    "                          (mdl, models[mdl])]) \n",
    "\n",
    "        for k in range(K):\n",
    "            # train the model using all but the kth fold\n",
    "            curr_mdl = mdl_base[mdl][k]\n",
    "\n",
    "            # get prediction on this dataset\n",
    "            if mdl == 'lasso':\n",
    "                curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "            else:\n",
    "                curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "                curr_prob = curr_prob[:,1]\n",
    "\n",
    "            # calculate score (AUROC)\n",
    "            curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "            # add score to list of scores\n",
    "            results_all[e][mdl].append(curr_score)\n",
    "\n",
    "        print('{} - {:10s} - AUROC {:0.3f} [{:0.3f}, {:0.3f}]'.format(dt.datetime.now(), e,\n",
    "                                                                    np.mean(results_all[e][mdl]),\n",
    "                                                                    np.min(results_all[e][mdl]),\n",
    "                                                                    np.max(results_all[e][mdl])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot a figure of the results\n",
    "marker = ['o','s','x','d']\n",
    "xi_str = ['Td=00','Td=04','Td=08','Td=16','Td=24']\n",
    "xi = [int(x[-2:]) for x in xi_str]\n",
    "\n",
    "plt.figure(figsize=[14,10])\n",
    "for m, mdl in enumerate(models):\n",
    "    all_score = list()\n",
    "    for i, x in enumerate(xi_str):\n",
    "        curr_score = results_all[x][mdl]\n",
    "\n",
    "        plt.plot(xi[i] * np.ones(len(curr_score)), curr_score,\n",
    "                marker=marker[m], color=col[m],\n",
    "                markersize=10, linewidth=2, linestyle=':')\n",
    "\n",
    "        all_score.append(np.median(curr_score))\n",
    "        \n",
    "    # plot a line through the mean across all evaluations\n",
    "\n",
    "    plt.plot(xi, all_score,\n",
    "            marker=marker[m], color=col[m],\n",
    "            markersize=10, linewidth=2, linestyle='-',\n",
    "            label=mdl)\n",
    "\n",
    "plt.gca().set_xticks(np.linspace(0,24,7))\n",
    "plt.gca().set_xlim([-1,25])\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend(loc='lower center',fontsize=16)\n",
    "plt.xlabel('Lead time (hours)',fontsize=18)\n",
    "plt.ylabel('AUROC',fontsize=18)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "\n",
    "plt.grid()\n",
    "#plt.savefig('auroc_over_time_dw24.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 5 # number of folds\n",
    "var_min, var_max, var_first, var_last, var_sum, var_first_early, var_last_early, var_static = mp.vars_of_interest()\n",
    "\n",
    "df_tmp=df_death.copy().merge(df_censor, how='left', left_on='icustay_id', right_on='icustay_id')\n",
    "time_dict = mp.generate_times(df_tmp, T=2, seed=111, censor=True)\n",
    "df_data = mp.get_design_matrix(df, time_dict, W=4, W_extra=24)\n",
    "\n",
    "# remove icustay_ids if they were censored (made DNR) before icu admission, or close enough to that\n",
    "idx = df_censor.loc[df_censor['censortime_hours']<=0, 'icustay_id']\n",
    "print('Removed {} icustay_id as they were censored on/before ICU admission.'.format((idx.shape[0])))\n",
    "df_data.drop(idx, axis=0, inplace=True)\n",
    "\n",
    "# get unique subject_id\n",
    "sid = np.sort(np.unique(df_death['subject_id'].values))\n",
    "\n",
    "# assign k-fold\n",
    "idxK_sid = np.random.permutation(sid.shape[0])\n",
    "idxK_sid = np.mod(idxK_sid,K)\n",
    "\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, df_death['subject_id'].values)\n",
    "\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(df_death.set_index('icustay_id')[['death']], left_index=True, right_index=True)\n",
    "\n",
    "# generate K-fold indices\n",
    "X = X.merge(df_death.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "\n",
    "# get unique subject_id\n",
    "sid = np.sort(np.unique(X['subject_id'].values))\n",
    "\n",
    "# assign k-fold\n",
    "idxK_sid = np.random.permutation(sid.shape[0])\n",
    "idxK_sid = np.mod(idxK_sid,K)\n",
    "\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "\n",
    "# drop the subject_id column\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "X_header = [x for x in df_data.columns.values] + var_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot a figure of the results\n",
    "marker = ['o','s','x','d']\n",
    "\n",
    "for m, mdl in enumerate(models):\n",
    "    all_score = list()\n",
    "    for i, x in enumerate(xi_str):\n",
    "        curr_score = results_all[x][mdl]\n",
    "\n",
    "        plt.plot(xi[i] * np.ones(len(curr_score)), curr_score,\n",
    "                marker=marker[m], color=col[m],\n",
    "                markersize=10, linewidth=2, linestyle=':')\n",
    "\n",
    "        all_score.append(np.median(curr_score))\n",
    "        \n",
    "    # plot a line through the mean across all evaluations\n",
    "\n",
    "    plt.plot(xi, all_score,\n",
    "            marker=marker[m], color=col[m],\n",
    "            markersize=10, linewidth=2, linestyle='-',\n",
    "            label=mdl)\n",
    "\n",
    "plt.gca().set_xticks(np.linspace(0,24,7))\n",
    "plt.gca().set_xlim([-1,25])\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend(loc='lower center',fontsize=16)\n",
    "plt.xlabel('Lead time (hours)',fontsize=18)\n",
    "plt.ylabel('AUROC',fontsize=18)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "\n",
    "plt.grid()\n",
    "#plt.savefig('auroc_over_time_dw24.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative feature importance at T=0 vs T=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B=100\n",
    "\n",
    "mdl = 'xgb'\n",
    "\n",
    "# apply the trained model to each dataset in experiments\n",
    "e1 = 'Td=24'\n",
    "e2 = 'Td=00'\n",
    "\n",
    "X1 = X_all[e1]\n",
    "y1 = y_all[e1]\n",
    "iid_curr1 = iid_all[e1]\n",
    "X2 = X_all[e2]\n",
    "y2 = y_all[e2]\n",
    "iid_curr2 = iid_all[e2]\n",
    "\n",
    "# map the k-fold indices from all IID to the subset included in this data\n",
    "idxMap = np.nonzero(np.in1d(iid,iid_curr1))[0]\n",
    "idxK1 = idxK_all[idxMap]\n",
    "idxMap = np.nonzero(np.in1d(iid,iid_curr2))[0]\n",
    "idxK2 = idxK_all[idxMap]\n",
    "\n",
    "imp1 = np.zeros([B,X1.shape[1]])\n",
    "imp2 = np.zeros([B,X2.shape[1]])\n",
    "\n",
    "for k in range(K):\n",
    "    # get model\n",
    "    curr_mdl = mdl_base[mdl][k]\n",
    "    print('========= {} ========='.format(mdl))\n",
    "    # get data\n",
    "    \n",
    "    # mess up one column at a time\n",
    "    for d in range(X.shape[1]):\n",
    "        for b in range(B):\n",
    "            X1_mess = X1.copy()\n",
    "            idxRand = np.random.randint(0, high=X1.shape[0], size=X1.shape[0])\n",
    "            X1_mess[:,d] = X1_mess[idxRand,d]\n",
    "            \n",
    "            X2_mess = X2.copy()\n",
    "            idxRand = np.random.randint(0, high=X2.shape[0], size=X2.shape[0])\n",
    "            X2_mess[:,d] = X2_mess[idxRand,d]\n",
    "            \n",
    "            # make predictions\n",
    "            if mdl == 'lasso':\n",
    "                curr_prob1 = curr_mdl.predict(X1_mess[idxK1 == k, :])\n",
    "                curr_prob2 = curr_mdl.predict(X2_mess[idxK2 == k, :])\n",
    "            else:\n",
    "                curr_prob1 = curr_mdl.predict_proba(X1_mess[idxK1 == k, :])\n",
    "                curr_prob1 = curr_prob1[:,1]\n",
    "                curr_prob2 = curr_mdl.predict_proba(X2_mess[idxK2 == k, :])\n",
    "                curr_prob2 = curr_prob2[:,1]\n",
    "\n",
    "            # average loss of prediction (dataset 1)\n",
    "            imp1[b,d] = metrics.log_loss(y1[idxK1 == k], curr_prob1)\n",
    "            # average loss of prediction (dataset 2)\n",
    "            imp2[b,d] = metrics.log_loss(y2[idxK2 == k], curr_prob2)\n",
    "            \n",
    "        if np.mod(d,10)==0:\n",
    "            print('{:3g} of {:3g}.'.format(d, X.shape[1]))\n",
    "\n",
    "\n",
    "# calculate difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(mp)\n",
    "mdl = 'xgb'\n",
    "\n",
    "xgb_model = mdl_base[mdl][0].steps[0][1]\n",
    "plt.figure(figsize=[14,20])\n",
    "ax = plt.gca()\n",
    "mp.plot_xgb_importance_fmap(xgb_model, X_header=X_header,\n",
    "                            importance_type='gain', ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
