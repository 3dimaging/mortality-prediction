{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties # for unicode fonts\n",
    "import psycopg2\n",
    "import sys\n",
    "import datetime as dt\n",
    "import mp_utils as mp\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# used to print out pretty pandas dataframes\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# used to impute mean for data and standardize for computational stability\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression is our favourite model ever\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV # l2 regularized regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# used to create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# gradient boosting - must download package https://github.com/dmlc/xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# below config used on pc70\n",
    "sqluser = 'alistairewj'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "query_schema = 'SET search_path to public,' + schema_name + ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exclusion criteria:\n",
    "#   - less than 16 years old\n",
    "#   - stayed in the ICU less than 4 hours\n",
    "#   - never have any chartevents data (i.e. likely administrative error)\n",
    "query = query_schema + \\\n",
    "\"\"\"\n",
    "select \n",
    "    subject_id, hadm_id, icustay_id\n",
    "from mp_cohort\n",
    "where excluded = 0\n",
    "\"\"\"\n",
    "co = pd.read_sql_query(query,con)\n",
    "\n",
    "# extract static vars into a separate dataframe\n",
    "df_static = pd.read_sql_query(query_schema + 'select * from mp_static_data', con)\n",
    "#for dtvar in ['intime','outtime','deathtime']:\n",
    "#    df_static[dtvar] = pd.to_datetime(df_static[dtvar])\n",
    "\n",
    "vars_static = [u'is_male', u'emergency_admission', u'age',\n",
    "               # services\n",
    "               u'service_any_noncard_surg',\n",
    "               u'service_any_card_surg',\n",
    "               u'service_cmed',\n",
    "               u'service_traum',\n",
    "               u'service_nmed',\n",
    "               # ethnicities\n",
    "               u'race_black',u'race_hispanic',u'race_asian',u'race_other',\n",
    "               # phatness\n",
    "               u'height', u'weight', u'bmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get ~5 million rows containing data from errbody\n",
    "# this takes a little bit of time to load into memory (~2 minutes)\n",
    "\n",
    "# %%time results\n",
    "# CPU times: user 42.8 s, sys: 1min 3s, total: 1min 46s\n",
    "# Wall time: 2min 7s\n",
    "\n",
    "df = pd.read_sql_query(query_schema + 'select * from mp_data', con)\n",
    "df.drop('subject_id',axis=1,inplace=True)\n",
    "df.drop('hadm_id',axis=1,inplace=True)\n",
    "df.sort_values(['icustay_id','hr'],axis=0,ascending=True,inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get death information\n",
    "df_death = pd.read_sql_query(query_schema + \"\"\"\n",
    "select \n",
    "co.icustay_id\n",
    ", ceil(extract(epoch from (co.outtime - co.intime))/60.0/60.0) as dischtime_hours\n",
    ", ceil(extract(epoch from (adm.deathtime - co.intime))/60.0/60.0) as deathtime_hours\n",
    ", case when adm.deathtime is null then 0 else 1 end as death\n",
    "from mp_cohort co\n",
    "inner join admissions adm\n",
    "on co.hadm_id = adm.hadm_id\n",
    "where co.excluded = 0\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get severity scores\n",
    "df_soi = pd.read_sql_query(query_schema + \"\"\"\n",
    "select \n",
    "co.icustay_id\n",
    ", case when adm.deathtime is null then 0 else 1 end as death\n",
    ", sa.saps\n",
    ", sa2.sapsii\n",
    ", aps.apsiii\n",
    ", so.sofa\n",
    ", lo.lods\n",
    ", oa.oasis\n",
    "from mp_cohort co\n",
    "inner join admissions adm\n",
    "on co.hadm_id = adm.hadm_id\n",
    "left join saps sa\n",
    "on co.icustay_id = sa.icustay_id\n",
    "left join sapsii sa2\n",
    "on co.icustay_id = sa2.icustay_id\n",
    "left join apsiii aps\n",
    "on co.icustay_id = aps.icustay_id\n",
    "left join sofa so\n",
    "on co.icustay_id = so.icustay_id\n",
    "left join lods lo\n",
    "on co.icustay_id = lo.icustay_id\n",
    "left join oasis oa\n",
    "on co.icustay_id = oa.icustay_id\n",
    "where co.excluded = 0\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manually define the time dictionary as admission+24 hours\n",
    "# since everything is relative to admission, we just fix the time to be 24 for all patients\n",
    "time_dict = df_death.copy().set_index('icustay_id')\n",
    "time_dict['windowtime'] = 24\n",
    "time_dict = time_dict['window_time'].to_dict()\n",
    "df_data = mp.get_design_matrix(df, time_dict, W=24, W_extra=24)\n",
    "\n",
    "# load the data into a numpy array\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[vars_static], how='left', left_index=True, right_index=True)\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(df_death.set_index('icustay_id')[['death']], left_index=True, right_index=True)\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "X_header = vars_static + [x for x in df_data.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = {'xgb': xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05),\n",
    "          'lasso': LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000),\n",
    "          'logreg': LogisticRegression(fit_intercept=True),\n",
    "          'rf': RandomForestClassifier()\n",
    "         }\n",
    "\n",
    "\n",
    "# create k-fold indices\n",
    "K = 5 # number of folds\n",
    "idxK = np.random.permutation(X.shape[0])\n",
    "idxK = np.mod(idxK,K)\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "pred_val = dict()\n",
    "tar_val = dict()\n",
    "\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    pred_val[mdl] = list()\n",
    "    tar_val[mdl] = list()\n",
    "\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "        \n",
    "        pred_val[mdl].append(curr_prob)\n",
    "        tar_val[mdl].append(y[idxK != k])\n",
    "        \n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "        \n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "        \n",
    "# calculate performance of severity of illness scores\n",
    "for mdl in ['saps','sapsii','apsiii','sofa','lods','oasis']:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    pred_val[mdl] = list()\n",
    "    tar_val[mdl] = list()\n",
    "    \n",
    "    for k in range(K):\n",
    "        curr_prob = df_soi.loc[idxK == k, mdl].values\n",
    "        \n",
    "        pred_val[mdl].append(curr_prob)\n",
    "        tar_val[mdl].append(y[idxK != k])\n",
    "        \n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "        \n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
