{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties # for unicode fonts\n",
    "import psycopg2\n",
    "import sys\n",
    "import datetime as dt\n",
    "import mp_utils as mp\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# used for train/test splits and cross validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# used to impute mean for data and standardize for computational stability\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression is our favourite model ever\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV # l2 regularized regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# used to create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# gradient boosting - must download package https://github.com/dmlc/xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# default colours for prettier plots\n",
    "col = [[0.9047, 0.1918, 0.1988],\n",
    "    [0.2941, 0.5447, 0.7494],\n",
    "    [0.3718, 0.7176, 0.3612],\n",
    "    [1.0000, 0.5482, 0.1000],\n",
    "    [0.4550, 0.4946, 0.4722],\n",
    "    [0.6859, 0.4035, 0.2412],\n",
    "    [0.9718, 0.5553, 0.7741],\n",
    "    [0.5313, 0.3359, 0.6523]];\n",
    "marker = ['v','o','d','^','s','o','+']\n",
    "ls = ['-','-','-','-','-','s','--','--']\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook outline\n",
    "\n",
    "This notebook will evaluate the mortality prediction model in the following contexts:\n",
    "\n",
    "* using a random time segment for each patient in the data\n",
    "* training using a random time segment, but evaluating using:\n",
    "    * 4 hours before death (or random time, if lived)\n",
    "    * same as the above, but at 8, 16, and 24 hours before death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# below config used on pc70\n",
    "sqluser = 'alistairewj'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "\n",
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "\n",
    "# exclusion criteria:\n",
    "#   - less than 16 years old\n",
    "#   - stayed in the ICU less than 4 hours\n",
    "#   - never have any chartevents data (i.e. likely administrative error)\n",
    "query = \\\n",
    "\"\"\"\n",
    "with t1 as\n",
    "(\n",
    "select ie.icustay_id\n",
    "    , adm.HOSPITAL_EXPIRE_FLAG\n",
    "    , ROW_NUMBER() over (partition by ie.subject_id order by intime) as rn\n",
    "from icustays ie\n",
    "inner join admissions adm\n",
    "    on ie.hadm_id = adm.hadm_id\n",
    "inner join patients pat\n",
    "    on ie.subject_id = pat.subject_id\n",
    "    and ie.intime > (pat.dob + interval '16' year)\n",
    "where adm.HAS_CHARTEVENTS_DATA = 1\n",
    "and \n",
    "not (\n",
    "       (lower(diagnosis) like '%organ donor%' and deathtime is not null)\n",
    "    or (lower(diagnosis) like '%donor account%' and deathtime is not null)\n",
    "    )\n",
    "and (ie.outtime - ie.intime) >= interval '4' hour\n",
    ")\n",
    "select \n",
    "    icustay_id\n",
    "    , HOSPITAL_EXPIRE_FLAG\n",
    "from t1\n",
    "\"\"\"\n",
    "co = pd.read_sql_query(query,con)\n",
    "co.set_index('icustay_id',inplace=True)\n",
    "\n",
    "# extract static vars into a separate dataframe\n",
    "df_static = pd.read_sql_query('select * from mpap_static_vars',con)\n",
    "for dtvar in ['intime','outtime','deathtime']:\n",
    "    df_static[dtvar] = pd.to_datetime(df_static[dtvar])\n",
    "df_static.set_index('icustay_id',inplace=True)\n",
    "\n",
    "cur.close()\n",
    "con.close()\n",
    "\n",
    "vars_static = [u'male', u'emergency', u'age',\n",
    "               u'cmed', u'csurg', u'surg', u'nsurg',\n",
    "               u'surg_other', u'traum', u'nmed',\n",
    "               u'omed', u'ortho', u'gu', u'gyn', u'ent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connect to the database and extract severity of illness scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "query = \\\n",
    "\"\"\"\n",
    "select \n",
    "    icustay_id\n",
    "    , oasis\n",
    "from oasis\n",
    "\"\"\"\n",
    "oa = pd.read_sql_query(query,con)\n",
    "oa.set_index('icustay_id',inplace=True)\n",
    "\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "query = \\\n",
    "\"\"\"\n",
    "select s.icustay_id, s.sofa\n",
    "from sofa s\n",
    "order by s.icustay_id\n",
    "\"\"\"\n",
    "\n",
    "sofa = pd.read_sql_query(query,con)\n",
    "sofa.set_index('icustay_id',inplace=True)\n",
    "\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "query = \\\n",
    "\"\"\"\n",
    "select s.icustay_id, s.saps\n",
    "from saps s\n",
    "order by s.icustay_id\n",
    "\"\"\"\n",
    "\n",
    "saps = pd.read_sql_query(query,con)\n",
    "saps.set_index('icustay_id',inplace=True)\n",
    "\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "query = \\\n",
    "\"\"\"\n",
    "select s.icustay_id, s.sapsii\n",
    "from sapsii s\n",
    "order by s.icustay_id\n",
    "\"\"\"\n",
    "\n",
    "sapsii = pd.read_sql_query(query,con)\n",
    "sapsii.set_index('icustay_id',inplace=True)\n",
    "\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "query = \\\n",
    "\"\"\"\n",
    "select icustay_id\n",
    ", APSIII\n",
    "from apsiii\n",
    "order by icustay_id\n",
    "\"\"\"\n",
    "\n",
    "apsiii = pd.read_sql_query(query,con)\n",
    "apsiii.set_index('icustay_id',inplace=True)\n",
    "\n",
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Using first 24 hours of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop through all the design matrices and get an idea of the CV performance of each.\n",
    "\n",
    "Here are some additional models worth considering:\n",
    "\n",
    "```python\n",
    "models = {'l2logreg': LogisticRegressionCV(penalty='l2',cv=5,fit_intercept=True),\n",
    "     'lasso': LassoCV(cv=5,fit_intercept=True),\n",
    "     'xgb': xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05),\n",
    "     'logreg': LogisticRegression(fit_intercept=True)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#analyses = ['base', 'base_nodeathfix', '00', '04', '08','16',\n",
    "#            '24','fixed', 'wt8', 'wt16', 'wt24',\n",
    "#            'wt8_00', 'wt8_08', 'wt8_16', 'wt8_24']\n",
    "\n",
    "seeds = {'base': 473010,\n",
    "        'base_nodeathfix': 217632,\n",
    "        '00': 724311,\n",
    "        '04': 952227,\n",
    "        '08': 721297,\n",
    "        '16': 968879,\n",
    "        '24': 608972,\n",
    "        'fixed': 585794,\n",
    "        'wt8': 176381,\n",
    "        'wt16': 658229,\n",
    "        'wt24': 635170,\n",
    "        'wt8_00': 34741,\n",
    "        'wt8_08': 95467,\n",
    "        'wt8_16': 85349,\n",
    "        'wt8_24': 89642,\n",
    "        'wt24_fixed': 761456}\n",
    "\n",
    "data_ext = 'base'\n",
    "\n",
    "# SVM parameters tuned by cross-validation\n",
    "#svm_parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                     'C': [1, 10]}\n",
    "\n",
    "# use a full grid over all parameters\n",
    "# specify parameters and distributions to sample from\n",
    "N_FEAT = X.shape[1]\n",
    "param_dist = {\"max_depth\": [3, 7, None],\n",
    "              \"max_features\": sp.stats.randint(1, N_FEAT),\n",
    "              \"min_samples_split\": sp.stats.randint(1, N_FEAT),\n",
    "              \"min_samples_leaf\": sp.stats.randint(1, N_FEAT),\n",
    "              \"n_estimators\": sp.stats.randint(50, 500),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# set up randomized search for RF\n",
    "n_iter_search = 20\n",
    "rf_random_search = RandomizedSearchCV(sklearn.ensemble.RandomForestClassifier(),\n",
    "                                      param_distributions=param_dist,\n",
    "                                      n_iter=n_iter_search)\n",
    "\n",
    "\n",
    "models = {'xgb': xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05),\n",
    "          'lasso': LassoCV(cv=5,fit_intercept=True),\n",
    "          'logreg': LogisticRegression(fit_intercept=True),\n",
    "          'rf': sklearn.ensemble.RandomForestClassifier(),\n",
    "          #'svm': GridSearchCV(sklearn.svm.SVC(kernel='rbf',class_weight='balanced',probability=False),\n",
    "          #                   svm_parameters, cv=5, scoring='roc_auc')\n",
    "         }\n",
    "\n",
    "results = dict()\n",
    "\n",
    "np.random.seed(seed=seeds[data_ext])\n",
    "\n",
    "# load the data into a numpy array\n",
    "X, y, X_header = mp.load_design_matrix(co,\n",
    "                                       df_additional_data=df_static[vars_static],\n",
    "                                       data_ext='_' + data_ext)\n",
    "\n",
    "print('{} - ========= {} ========='.format(dt.datetime.now(), data_ext))\n",
    "\n",
    "scores = list()\n",
    "for i, mdl in enumerate(models):\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])])\n",
    "\n",
    "\n",
    "    curr_score = cross_val_score(estimator, X, y, scoring='roc_auc',cv=5)\n",
    "\n",
    "    print('{} - {:10s} {:0.4f} [{:0.4f}, {:0.4f}]'.format(dt.datetime.now(), mdl,\n",
    "                                                          np.mean(curr_score),\n",
    "                                                          np.min(curr_score), np.max(curr_score)))\n",
    "\n",
    "    # save the score to a dictionary\n",
    "    results[mdl] = curr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#analyses = ['base', 'base_nodeathfix', '00', '04', '08','16',\n",
    "#            '24','fixed', 'wt8', 'wt16', 'wt24',\n",
    "#            'wt8_00', 'wt8_08', 'wt8_16', 'wt8_24']\n",
    "\n",
    "seeds = {'base': 473010,\n",
    "        'base_nodeathfix': 217632,\n",
    "        '00': 724311,\n",
    "        '04': 952227,\n",
    "        '08': 721297,\n",
    "        '16': 968879,\n",
    "        '24': 608972,\n",
    "        'fixed': 585794,\n",
    "        'wt8': 176381,\n",
    "        'wt16': 658229,\n",
    "        'wt24': 635170,\n",
    "        'wt8_00': 34741,\n",
    "        'wt8_08': 95467,\n",
    "        'wt8_16': 85349,\n",
    "        'wt8_24': 89642,\n",
    "        'wt24_fixed': 761456}\n",
    "\n",
    "data_ext = 'wt24_fixed'\n",
    "\n",
    "# SVM parameters tuned by cross-validation\n",
    "#svm_parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                     'C': [1, 10]}\n",
    "\n",
    "# use a full grid over all parameters\n",
    "# specify parameters and distributions to sample from\n",
    "N_FEAT = X.shape[1]\n",
    "param_dist = {\"max_depth\": [3, 7, None],\n",
    "              \"max_features\": sp.stats.randint(1, N_FEAT),\n",
    "              \"min_samples_split\": sp.stats.randint(1, N_FEAT),\n",
    "              \"min_samples_leaf\": sp.stats.randint(1, N_FEAT),\n",
    "              \"n_estimators\": sp.stats.randint(50, 500),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# set up randomized search for RF\n",
    "n_iter_search = 20\n",
    "rf_random_search = RandomizedSearchCV(sklearn.ensemble.RandomForestClassifier(),\n",
    "                                      param_distributions=param_dist,\n",
    "                                      n_iter=n_iter_search)\n",
    "\n",
    "\n",
    "models = {'xgb': xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05),\n",
    "          'lasso': LassoCV(cv=5,fit_intercept=True),\n",
    "          'logreg': LogisticRegression(fit_intercept=True),\n",
    "          'rf': sklearn.ensemble.RandomForestClassifier(),\n",
    "          #'svm': GridSearchCV(sklearn.svm.SVC(kernel='rbf',class_weight='balanced',probability=False),\n",
    "          #                   svm_parameters, cv=5, scoring='roc_auc')\n",
    "         }\n",
    "\n",
    "results = dict()\n",
    "\n",
    "np.random.seed(seed=seeds[data_ext])\n",
    "\n",
    "# load the data into a numpy array\n",
    "X, y, X_header = mp.load_design_matrix(co,\n",
    "                                       df_additional_data=df_static[vars_static],\n",
    "                                       data_ext='_' + data_ext)\n",
    "\n",
    "print('{} - ========= {} ========='.format(dt.datetime.now(), data_ext))\n",
    "\n",
    "scores = list()\n",
    "for i, mdl in enumerate(models):\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])])\n",
    "\n",
    "\n",
    "    curr_score = cross_val_score(estimator, X, y, scoring='roc_auc',cv=5)\n",
    "\n",
    "    print('{} - {:10s} {:0.4f} [{:0.4f}, {:0.4f}]'.format(dt.datetime.now(), mdl,\n",
    "                                                          np.mean(curr_score),\n",
    "                                                          np.min(curr_score), np.max(curr_score)))\n",
    "\n",
    "    # save the score to a dictionary\n",
    "    results[mdl] = curr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare to severity of illness scores\n",
    "df = co\n",
    "\n",
    "# merge in the various severity scores\n",
    "df = df.merge(oa, how='left', left_index=True,right_index=True,suffixes=('','_oasis'))\n",
    "df = df.merge(sofa, how='left', left_index=True,right_index=True,suffixes=('','_sofa'))\n",
    "df = df.merge(saps, how='left', left_index=True,right_index=True,suffixes=('','_saps'))\n",
    "df = df.merge(sapsii, how='left', left_index=True,right_index=True,suffixes=('','_sapsii'))\n",
    "df = df.merge(apsiii, how='left', left_index=True,right_index=True,suffixes=('','_apsiii'))\n",
    "\n",
    "\n",
    "for v in df.columns:\n",
    "    if v != 'hospital_expire_flag':\n",
    "        print('{:8s} - {:0.4f}'.format(v,metrics.roc_auc_score(df['hospital_expire_flag'],df[v])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "mdl = 'xgb'\n",
    "\n",
    "print('=================== {} ==================='.format(mdl))\n",
    "\n",
    "for data_ext in np.sort(results_val.keys()):\n",
    "    curr_score = results[mdl][data_ext]\n",
    "    print('{:15s} - {:0.4f} [{:0.4f} - {:0.4f}]'.format(data_ext, np.mean(curr_score), np.min(curr_score), np.max(curr_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above reported cross-validation performance in a variety of settings. We're also interested in *evaluating* the same model in the various settings. That is, training a model using random offsets, and then evaluating how it performs 4 hours before death, 8 hours, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the data used to train the model\n",
    "data_ext = 'base'\n",
    "np.random.seed(seed=seeds[data_ext])\n",
    "\n",
    "# load the data into a numpy array\n",
    "X, y, X_header = mp.load_design_matrix(co,\n",
    "                                       df_additional_data=df_static[vars_static],\n",
    "                                       data_ext=data_ext)\n",
    "\n",
    "\n",
    "    \n",
    "# load into a dictionary the other various datasets/models\n",
    "X_val = dict()\n",
    "y_val = dict()\n",
    "X_header_val = dict()\n",
    "results_val = dict() # stores AUROCs across datasets\n",
    "mdl_val = dict() # stores the model trained across k-folds\n",
    "\n",
    "for i, data_ext in enumerate(analyses):\n",
    "\n",
    "    # load the data into a numpy array\n",
    "    X_val[data_ext], y_val[data_ext], X_header_val[data_ext] = mp.load_design_matrix(co,\n",
    "                                           df_additional_data=df_static[vars_static],\n",
    "                                           data_ext=data_ext)\n",
    "    results_val[data_ext] = dict()\n",
    "    \n",
    "print('{} - Finished loading data'.format(dt.datetime.now()))\n",
    "\n",
    "np.random.seed(seed=seeds[data_ext])\n",
    "\n",
    "# create k-fold indices\n",
    "K = 5 # number of folds\n",
    "idxK = np.random.permutation(X.shape[0])\n",
    "idxK = np.mod(idxK,K)\n",
    "\n",
    "mdl = 'xgb'\n",
    "mdl_val[mdl] = list()\n",
    "\n",
    "\n",
    "for data_ext in X_val:\n",
    "    results_val[data_ext][mdl] = list() # initialize list for scores\n",
    "\n",
    "# no pre-processing of data necessary for xgb\n",
    "estimator = Pipeline([(mdl, models[mdl])])    \n",
    "\n",
    "for k in range(K):\n",
    "    # train the model using all but the kth fold\n",
    "    curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "    for data_ext in X_val:\n",
    "        # get prediction on this dataset\n",
    "        curr_prob = curr_mdl.predict_proba(X_val[data_ext][idxK == k, :])\n",
    "        curr_prob = curr_prob[:,1]\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y_val[data_ext][idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[data_ext][mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "    \n",
    "    print('{} - Finished fold {} of {}.'.format(dt.datetime.now(), k+1, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "mdl = 'xgb'\n",
    "\n",
    "print('=================== {} ==================='.format(mdl))\n",
    "\n",
    "for data_ext in np.sort(results_val.keys()):\n",
    "    curr_score = results_val[data_ext][mdl]\n",
    "    print('{:15s} - {:0.4f} [{:0.4f} - {:0.4f}]'.format(data_ext, np.mean(curr_score), np.min(curr_score), np.max(curr_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same experiment as above, but this time, let's train a model with the outcome \"did the patient die in the next 24 hours?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the data\n",
    "np.random.seed(seed=seeds[data_ext])\n",
    "data_ext = 'base'\n",
    "\n",
    "# load the data into a numpy array\n",
    "X, y, X_header = mp.load_design_matrix(co,\n",
    "                                       df_additional_data=df_static[vars_static],\n",
    "                                       data_ext=data_ext,\n",
    "                                       diedWithin=24)\n",
    "\n",
    "# load into a dictionary the other various datasets/models\n",
    "X_val = dict()\n",
    "y_val = dict()\n",
    "X_header_val = dict()\n",
    "results_val = dict() # stores AUROCs across datasets\n",
    "mdl_val = dict() # stores the model trained across k-folds\n",
    "\n",
    "for i, data_ext in enumerate(analyses):\n",
    "\n",
    "    # load the data into a numpy array\n",
    "    X_val[data_ext], y_val[data_ext], X_header_val[data_ext] = mp.load_design_matrix(co,\n",
    "                                           df_additional_data=df_static[vars_static],\n",
    "                                           data_ext='_' + data_ext)\n",
    "    results_val[data_ext] = dict()\n",
    "    \n",
    "print('{} - Finished loading data'.format(dt.datetime.now()))\n",
    "\n",
    "np.random.seed(seed=seeds[data_ext])\n",
    "\n",
    "# create k-fold indices\n",
    "K = 5 # number of folds\n",
    "idxK = np.random.permutation(X.shape[0])\n",
    "idxK = np.mod(idxK,K)\n",
    "\n",
    "mdl = 'xgb'\n",
    "mdl_val[mdl] = list()\n",
    "\n",
    "\n",
    "for data_ext in X_val:\n",
    "    results_val[data_ext][mdl] = list() # initialize list for scores\n",
    "\n",
    "# no pre-processing of data necessary for xgb\n",
    "estimator = Pipeline([(mdl, models[mdl])])    \n",
    "\n",
    "for k in range(K):\n",
    "    # train the model using all but the kth fold\n",
    "    curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "    for data_ext in X_val:\n",
    "        # get prediction on this dataset\n",
    "        curr_prob = curr_mdl.predict_proba(X_val[data_ext][idxK == k, :])\n",
    "        curr_prob = curr_prob[:,1]\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y_val[data_ext][idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[data_ext][mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "    \n",
    "    print('{} - Finished fold {} of {}.'.format(dt.datetime.now(), k+1, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the results\n",
    "mdl = 'xgb'\n",
    "\n",
    "print('=================== {} ==================='.format(mdl))\n",
    "\n",
    "for data_ext in np.sort(results_val.keys()):\n",
    "    curr_score = results_val[data_ext][mdl]\n",
    "    print('{:15s} - {:0.4f} [{:0.4f} - {:0.4f}]'.format(data_ext, np.mean(curr_score), np.min(curr_score), np.max(curr_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an estimate of how well these models do in cross-validation. The next step will be to take the best model and optimize it appropriately using only a training subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training / test sets\n",
    "np.random.seed(seed=324875)\n",
    "icustay_id = co.index.values\n",
    "idxTest = np.random.rand(X.shape[0]) > 0.20\n",
    "X_train = X[~idxTest,:]\n",
    "y_train = y[~idxTest]\n",
    "iid_train = icustay_id[~idxTest]\n",
    "\n",
    "X_test = X[idxTest,:]\n",
    "y_test = y[idxTest]\n",
    "iid_test = icustay_id[~idxTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters of a model using only the training set\n",
    "# takes ~20 minutes\n",
    "\n",
    "# first train it w/o grid search\n",
    "xgb_nopreproc = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "xgb_nopreproc = xgb_nopreproc.fit(X_train, y_train)\n",
    "\n",
    "# parameters with multiple values will be used in the grid search\n",
    "grid_params = {\n",
    "         'max_depth': [4,7], # max depth of the tree\n",
    "         'learning_rate': [0.05, 0.3], # step size shrinkage, makes earlier trees less important over time\n",
    "         'n_estimators': [300, 1000], # number of trees built\n",
    "         'subsample': [0.3, 0.8] # subsample the data when fitting each tree (prevent overfitting)\n",
    "         }\n",
    "\n",
    "default_params = {'colsample_bytree': 1,\n",
    "                  'colsample_bylevel':1,\n",
    "                  'silent':1,\n",
    "                  'reg_lambda':1, # L2 regularization on weights\n",
    "                  'reg_alpha':0, # L1 regularization on weights\n",
    "                  'objective':'binary:logistic'}\n",
    "\n",
    "init_model = xgb.XGBClassifier(**default_params)\n",
    "\n",
    "# the pipeline here is redundant - but could be useful if you want to add any custom preprocessing\n",
    "# for example, creating binary features from categories, etc...\n",
    "# the custom function only has to implement 'fit' and 'transform'\n",
    "estimator = Pipeline([(\"xgb\", GridSearchCV(init_model, grid_params, verbose=1))])\n",
    "\n",
    "xgb_model_cv = estimator.fit(X_train,y_train)\n",
    "\n",
    "# generate class probabilities\n",
    "y_prob = xgb_model_cv.predict_proba(X_test)\n",
    "y_prob = y_prob[:, 1]\n",
    "\n",
    "# predict class labels for the test set\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# get the original xgb predictions without cross-validation\n",
    "# gives us a rough idea of the improvement of selecting some of the parameters\n",
    "y_prob_nocv = xgb_nopreproc.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('\\n --- Performance on 20% held out test set --- \\n')\n",
    "# generate evaluation metrics\n",
    "print('Accuracy = {:0.3f}'.format(metrics.accuracy_score(y_test, y_pred)))            \n",
    "print('AUROC = {:0.3f} (unoptimized model was {:0.3f})'.format(metrics.roc_auc_score(y_test, y_prob),\n",
    "                                                               metrics.roc_auc_score(y_test, y_prob_nocv)))\n",
    "\n",
    "\n",
    "mp.print_cm(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above optimized hyperparameters, train the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#best_params = xgb_model_cv.get_params()['xgb'].best_params_\n",
    "xgb_model = xgb.XGBClassifier(**default_params)\n",
    "#xgb_model = xgb_model.set_params(**best_params)\n",
    "xgb_model = xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature importance!\n",
    "plt.figure(figsize=[14,40])\n",
    "ax = plt.gca()\n",
    "mp.plot_xgb_importance_fmap(xgb_model, X_header=X_header, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is just too slow :(\n",
    "\n",
    "```python\n",
    "# speed up SVM\n",
    "\n",
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                  strategy=\"mean\",\n",
    "                                  axis=0)),\n",
    "              (\"scaler\", sklearn.preprocessing.MinMaxScaler()),\n",
    "              (\"svm\", sklearn.svm.SVC(cache_size=6000))])\n",
    "\n",
    "for n in [100,1000,10000]:\n",
    "    print(n)\n",
    "    %timeit estimator.fit(X[0:n,:],y[0:n])\n",
    "```\n",
    "\n",
    "~10,000 samples take ~5s and that's using default parameters.\n",
    "\n",
    "```python\n",
    "# speed up SVM with bagging\n",
    "n_estimators = 10\n",
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                  strategy=\"mean\",\n",
    "                                  axis=0)),\n",
    "              (\"scaler\", sklearn.preprocessing.MinMaxScaler()),\n",
    "              (\"svm_bagged\", BaggingClassifier(sklearn.svm.SVC(kernel='linear',\n",
    "                                                  probability=False,\n",
    "                                                  class_weight='balanced',\n",
    "                                                  cache_size=6000), \n",
    "                                               max_samples = 1.0 / n_estimators,\n",
    "                                               n_estimators=n_estimators,\n",
    "                                               bootstrap=False))])\n",
    "\n",
    "for n in [100,1000,10000]:\n",
    "    print(n)\n",
    "    %timeit estimator.fit(X[0:n,:],y[0:n])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
