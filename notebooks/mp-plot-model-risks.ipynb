{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties # for unicode fonts\n",
    "import psycopg2\n",
    "import sys\n",
    "import datetime as dt\n",
    "import mp_utils as mp\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# used for train/test splits and cross validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# used to impute mean for data and standardize for computational stability\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression is our favourite model ever\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV # l2 regularized regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# used to create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# gradient boosting - must download package https://github.com/dmlc/xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# default colours for prettier plots\n",
    "col = [[0.9047, 0.1918, 0.1988],\n",
    "    [0.2941, 0.5447, 0.7494],\n",
    "    [0.3718, 0.7176, 0.3612],\n",
    "    [1.0000, 0.5482, 0.1000],\n",
    "    [0.4550, 0.4946, 0.4722],\n",
    "    [0.6859, 0.4035, 0.2412],\n",
    "    [0.9718, 0.5553, 0.7741],\n",
    "    [0.5313, 0.3359, 0.6523]];\n",
    "marker = ['v','o','d','^','s','o','+']\n",
    "ls = ['-','--','-.',':','-','s','--','--']\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below config used on pc70\n",
    "sqluser = 'alistairewj'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "\n",
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "\n",
    "# exclusion criteria:\n",
    "#   - less than 16 years old\n",
    "#   - stayed in the ICU less than 4 hours\n",
    "#   - never have any chartevents data (i.e. likely administrative error)\n",
    "query = \\\n",
    "\"\"\"\n",
    "with t1 as\n",
    "(\n",
    "select ie.icustay_id\n",
    "    , adm.HOSPITAL_EXPIRE_FLAG\n",
    "    , ROW_NUMBER() over (partition by ie.subject_id order by intime) as rn\n",
    "from icustays ie\n",
    "inner join admissions adm\n",
    "    on ie.hadm_id = adm.hadm_id\n",
    "inner join patients pat\n",
    "    on ie.subject_id = pat.subject_id\n",
    "    and pat.dob < ie.intime - interval '16' year\n",
    "where adm.HAS_CHARTEVENTS_DATA = 1\n",
    "and (ie.outtime - ie.intime) >= interval '4' hour\n",
    ")\n",
    "select \n",
    "    icustay_id\n",
    "    , HOSPITAL_EXPIRE_FLAG\n",
    "from t1\n",
    "\"\"\"\n",
    "co = pd.read_sql_query(query,con)\n",
    "co.set_index('icustay_id',inplace=True)\n",
    "\n",
    "# extract static vars into a separate dataframe\n",
    "df_static = pd.read_sql_query('select * from mpap_static_vars',con)\n",
    "for dtvar in ['intime','outtime','deathtime']:\n",
    "    df_static[dtvar] = pd.to_datetime(df_static[dtvar])\n",
    "df_static.set_index('icustay_id',inplace=True)\n",
    "\n",
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modelling of this data will proceed in two stages:\n",
    "\n",
    "1. A cross-validation estimate of the performance of the Gradient Boosting Decision Trees (GBDT) model (via xgboost) vs. standard regression models will be reported\n",
    "2. A single model using *most* of the data (90%) will be created using GBDT - then this model will be qualitatively evaluated on a subset of the held out 10% across their entire stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_static = [u'male', u'emergency', u'age',\n",
    "               u'cmed', u'csurg', u'surg', u'nsurg',\n",
    "               u'surg_other', u'traum', u'nmed',\n",
    "               u'omed', u'ortho', u'gu', u'gyn', u'ent']\n",
    "\n",
    "data_ext = 'base'\n",
    "\n",
    "# load the data into a numpy array\n",
    "X, y, X_header = mp.load_design_matrix(co,\n",
    "                                       df_additional_data=df_static[vars_static],\n",
    "                                       data_ext='_' + data_ext,\n",
    "                                      path='./data/')\n",
    "\n",
    "icustay_id = co.index.values\n",
    "\n",
    "# split into train/test\n",
    "np.random.seed(seed=324875)\n",
    "idxTest = np.random.rand(X.shape[0]) > 0.05\n",
    "X_train = X[~idxTest,:]\n",
    "y_train = y[~idxTest]\n",
    "iid_train = icustay_id[~idxTest]\n",
    "\n",
    "X_test = X[idxTest,:]\n",
    "y_test = y[idxTest]\n",
    "iid_test = icustay_id[~idxTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create xgb using train\n",
    "xgb_model = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "xgb_fit = xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_test_mv = mp.query_metavision_patients(iid_test)\n",
    "iid_test_mv = iid_test_mv[iid_test_mv<210000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to plot patient data\n",
    "\n",
    "This function will, given an ICUSTAY_ID, read the csv of data for the patient, plot their risk, and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, iid_curr in enumerate(iid_test_mv):\n",
    "    plt_and_save(iid_curr, plotText=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on a single patient\n",
    "\n",
    "Here we:\n",
    "\n",
    "1. Load data for a single patient from csv\n",
    "    * this dataframe has patient observations at every charttime\n",
    "2. Generate a dataframe with the extracted features for every charttime\n",
    "3. Apply the model to each row of this dataframe\n",
    "4. Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prints out three random test cases which we have .csv files for\n",
    "# we only saved csv files for ICUSTAY_ID < 210000, to save space\n",
    "iid_test[iid_test < 210000][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a single individual's data from saved csv files (for convenience)\n",
    "iid = 202887 # 202887 #200806 # 206719, 203461, 207012\n",
    "# 202887, 207046, 200806, 205803, 201975, 209108 are metavision patients\n",
    "df_curr = pd.read_csv('./data/' + str(iid) + '.0.csv')\n",
    "df_curr.set_index('charttime_elapsed',inplace=True)\n",
    "\n",
    "# this can take ~10-30 seconds to generate the features for all the rows\n",
    "df_x = mp.extract_feature_across_sp(df_curr)\n",
    "X_curr = df_x.values.astype(float)\n",
    "\n",
    "# add in the static variables\n",
    "X_static = np.tile(df_static.loc[iid,vars_static].values, [X_curr.shape[0],1]).astype(float)\n",
    "X_curr = np.column_stack([X_curr, X_static])\n",
    "\n",
    "# create the outcome\n",
    "y_curr = np.tile( co.loc[iid,'hospital_expire_flag'], [X_curr.shape[0],] )\n",
    "\n",
    "# generate probability for the window selected for this patient\n",
    "y_prob = xgb_model.predict_proba(X_curr)\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "# plot this probability over time\n",
    "t = df_x.index.values/60.0/60.0 + 4.0 # convert to hours, add offset so t indexes the *end* time\n",
    "\n",
    "\n",
    "#df_x.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,12])\n",
    "plt.plot(t,y_prob,'-',color=col[0],linewidth=2)\n",
    "\n",
    "plt.xlabel('Time (hours)',fontsize=16)\n",
    "plt.ylabel('Risk',fontsize=16)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "# what changed to cause these large spikes?\n",
    "idxBigJump = np.where((y_prob[1:] - y_prob[0:-1]) > 0.1)[0] + 1\n",
    "\n",
    "ylim = plt.ylim()\n",
    "\n",
    "for i, val in enumerate(idxBigJump):\n",
    "    #print(i, val)\n",
    "    X_big = X_curr[val,:]\n",
    "    X_sml = X_curr[val-1,:]\n",
    "    \n",
    "    idxDiff = np.where(abs(X_big - X_sml) > 1e-4)[0]\n",
    "    \n",
    "    # now look for *big* differences\n",
    "    \n",
    "    # get anchors for plot locations\n",
    "    anchor_x = t[val]\n",
    "    anchor_y = ylim[1]-0.1*(ylim[1]-ylim[0]) # the higher prob\n",
    "    \n",
    "    for m, mval in enumerate(idxDiff):\n",
    "        if X_big[mval] > X_sml[mval]:\n",
    "            txt_for_plot = '^   ' + X_header[mval]\n",
    "        else:\n",
    "            txt_for_plot = ' v  ' + X_header[mval]\n",
    "            \n",
    "        plt.plot([anchor_x, anchor_x], [0.0,0.9], '--', color='k', linewidth=2)\n",
    "        plt.text(anchor_x+1,anchor_y-(m*0.02),txt_for_plot,fontsize=14)\n",
    "            \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.loc[[202887, 200806, 206719, 203461, 207012, 202887, 207046, 200806, 205803, 201975, 209108],'hospital_expire_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iids = [202887, 203461, 207012, 207046]\n",
    "\n",
    "col_map = {202887: col[1],\n",
    "          203461: col[2],\n",
    "          207012: col[0],\n",
    "          207046: col[3]}\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "for i, iid in enumerate(iids):\n",
    "    # load in a single individual's data from saved csv files (for convenience)\n",
    "    df_curr = pd.read_csv('./data/' + str(iid) + '.0.csv')\n",
    "    df_curr.set_index('charttime_elapsed',inplace=True)\n",
    "\n",
    "    # this can take ~10-30 seconds to generate the features for all the rows\n",
    "    df_x = mp.extract_feature_across_sp(df_curr)\n",
    "    X_curr = df_x.values.astype(float)\n",
    "\n",
    "    # add in the static variables\n",
    "    X_static = np.tile(df_static.loc[iid,vars_static].values, [X_curr.shape[0],1]).astype(float)\n",
    "    X_curr = np.column_stack([X_curr, X_static])\n",
    "\n",
    "    # create the outcome\n",
    "    y_curr = co.loc[iid,'hospital_expire_flag']\n",
    "\n",
    "    # generate probability for the window selected for this patient\n",
    "    y_prob = xgb_model.predict_proba(X_curr)\n",
    "    y_prob = y_prob[:,1]\n",
    "\n",
    "    # plot this probability over time\n",
    "    t = df_x.index.values/60.0/60.0 + 4.0 # convert to hours, add offset so t indexes the *end* time\n",
    "\n",
    "\n",
    "    #df_x.head(n=20)\n",
    "    if y_curr == 0:\n",
    "        lbl = 'ID {} - survived'.format(iid)\n",
    "    else:\n",
    "        lbl = 'ID {} - expired'.format(iid)\n",
    "        \n",
    "    plt.plot(t,y_prob,'-',color=col_map[iid], linestyle='-', marker='o', linewidth=4, label=lbl)\n",
    "\n",
    "\n",
    "plt.xlabel('Time since ICU admission (hours)',fontsize=18)\n",
    "plt.ylabel('Risk of mortality',fontsize=18)\n",
    "plt.legend(loc='upper left',fontsize=16)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "\n",
    "plt.savefig('example_risks.pdf')\n",
    "plt.savefig('example_risks.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = mp.query_infusions(iid)\n",
    "inputs['icustarttimehr'] = inputs['icustarttime'] / np.timedelta64(1,'h')\n",
    "inputs['icuendtimehr'] = inputs['icuendtime'] / np.timedelta64(1,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codestatus = mp.query_codestatus(iid) # takes 2-3 minutes\n",
    "if codestatus.shape[0]>0:\n",
    "    codestatus['icutimehr'] = codestatus['icutime'] / np.timedelta64(1,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample data over first 24 hours from admission to ICU\n",
    "# Credit: Randal Olson for styling (http://www.randalolson.com/2014/06/28/)\n",
    "\n",
    "# Prepare the size of the figure\n",
    "fig = plt.figure(figsize=(22, 20))\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "# \"Tableau 20\" colors as RGB.   \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "    \n",
    "# Remove the plot frame lines. \n",
    "ax = plt.subplot(111)    \n",
    "ax.spines[\"top\"].set_visible(False)    \n",
    "ax.spines[\"bottom\"].set_visible(True)    \n",
    "ax.spines[\"right\"].set_visible(False)    \n",
    "ax.spines[\"left\"].set_visible(True)    \n",
    "  \n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.      \n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left() \n",
    "ax.axis([0,60,0,225])\n",
    "\n",
    "# Plot risk\n",
    "plt.plot(t,100.0*y_prob,'-',\n",
    "         label='Risk of mortality (%)',\n",
    "         color=col[0],linewidth=2)\n",
    "\n",
    "\n",
    "# Plot input/output events\n",
    "plt.plot(inputs.icustarttimehr[inputs.amountuom=='mL'], \n",
    "         inputs.amount[inputs.amountuom=='mL'].cumsum()/100, \n",
    "         color=tableau20[9], lw=2.5,\n",
    "         marker='o', markersize=6, label='Intake volume, dL')\n",
    "\n",
    "#plt.plot(outputs.icutimehr, \n",
    "#         outputs.value.cumsum()/100, \n",
    "#         color=tableau20[10], lw=2.5,\n",
    "#         marker='o', markersize=6, label='Output volume, dL')\n",
    "\n",
    "# Plot intravenous meds\n",
    "\n",
    "iv_meds = [x for x in inputs.label.unique()\n",
    "           if x != 'Gastric Meds'\n",
    "           and x != 'PO Intake']\n",
    "\n",
    "for m, med in enumerate(iv_meds):\n",
    "    y_loc = 165-(m*5) # where on the y-axis the data is plotted\n",
    "    unit = [x for x in inputs.loc[inputs['label']==med,'rateuom'].unique()\n",
    "        if x != '']\n",
    "    if len(unit)>0:\n",
    "        unit = ', ' + str(unit[0])\n",
    "    else:\n",
    "        unit = ''\n",
    "    \n",
    "    plt.text(np.max(inputs.icuendtimehr)+0.5,y_loc,med + unit,fontsize=17)\n",
    "    \n",
    "    for i,row in inputs.loc[(inputs[\"label\"] == med) & (inputs[\"rate\"] > 0)].iterrows():\n",
    "        plt.plot([row['icustarttimehr'],row['icuendtimehr']],[y_loc]*2,\n",
    "                 color=tableau20[16], lw=4,marker='o', markersize=6)\n",
    "        plt.text(row['icustarttimehr'], y_loc,\n",
    "                 str(round(row['rate'],1)),\n",
    "                 fontsize=15)\n",
    "        \n",
    "    if inputs.loc[(inputs[\"label\"] == med) & (inputs[\"rate\"] > 0)].shape[0] == 0:\n",
    "        plt.plot(inputs.icustarttimehr[inputs.label==med],\n",
    "                  [y_loc+1.5]*len(inputs[inputs.label==med]),\n",
    "                  color=tableau20[16], lw=0, marker='o', markersize=6)\n",
    "        # dashed line to guide the eye\n",
    "        plt.plot([0,np.max(inputs.icuendtimehr)],\n",
    "                  [y_loc+1.5]*2,\n",
    "                  color=[0.3,0.3,0.3], lw=2, linestyle=':', markersize=6)\n",
    "\n",
    "# Plot code status\n",
    "if codestatus.shape[0]>0:\n",
    "    plt.text(-10,220,'Code status',fontsize=17) \n",
    "    for i, txt in enumerate(codestatus.value[codestatus.label=='Code Status'].values):\n",
    "            plt.annotate(txt, (codestatus.icutimehr[codestatus.label=='Code Status'].\n",
    "                               values[i],220),fontsize=17)\n",
    "        \n",
    "plt.legend(loc=5,fontsize=18)\n",
    "plt.xlabel('Time after admission to the intensive care unit, hours', fontsize=22)\n",
    "plt.ylabel('Measurement, absolute value', fontsize=22)\n",
    "plt.yticks(np.arange(0, 140, 20))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_and_save(iid, plotText=True):\n",
    "    # load in a single individual's data from saved csv files (for convenience)\n",
    "    df_curr = pd.read_csv('./data/' + str(iid) + '.csv')\n",
    "    df_curr['charttime'] = pd.to_datetime(df_curr['charttime'])\n",
    "\n",
    "    # change charttime into time elapsed\n",
    "    df_curr['timeelapsed'] = (df_curr['charttime'] - df_static.loc[iid,'intime']) / np.timedelta64(1, 'm')\n",
    "    df_curr.set_index('timeelapsed',inplace=True)\n",
    "    df_curr.head()\n",
    "\n",
    "    # this can take ~10-30 seconds to generate the features for all the rows\n",
    "    df_x = mp.extract_feature_across_sp(df_curr)\n",
    "    X_curr = df_x.values.astype(float)\n",
    "\n",
    "    # add in the static variables\n",
    "    X_static = np.tile(df_static.loc[iid,vars_static].values, [X_curr.shape[0],1]).astype(float)\n",
    "    X_curr = np.column_stack([X_curr, X_static])\n",
    "\n",
    "    if iid not in co.index:\n",
    "        return\n",
    "    \n",
    "    # create the outcome\n",
    "    y_curr = np.tile( co.loc[iid,'hospital_expire_flag'], [X_curr.shape[0],] )\n",
    "\n",
    "    # generate probability for the window selected for this patient\n",
    "    y_prob = xgb_model.predict_proba(X_curr)\n",
    "    y_prob = y_prob[:,1]\n",
    "\n",
    "    # plot this probability over time\n",
    "    t = df_x.index.values/60.0 + 4.0 # convert to hours, add offset so t indexes the *end* time\n",
    "    \n",
    "    fig = plt.figure(figsize=[12,9])\n",
    "    plt.plot(t,y_prob,'-',color=col[0],linewidth=2)\n",
    "    \n",
    "    # plot time of death\n",
    "    if str(df_static.loc[iid_curr,'deathtime']) != 'NaT':\n",
    "        tod = (df_static.loc[iid,'deathtime'] - df_static.loc[iid, 'intime']) / np.timedelta64(1, 'h')\n",
    "        plt.plot([tod,tod], [0,1], linestyle='--', lw=3, color=col[4])\n",
    "        hosp_exp = '1'\n",
    "    else:\n",
    "        hosp_exp = '0'\n",
    "        \n",
    "    plt.xlabel('Time (hours)',fontsize=16)\n",
    "    plt.ylabel('Risk',fontsize=16)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0,1])\n",
    "    \n",
    "    if plotText == True:\n",
    "        # what changed to cause these large spikes?\n",
    "        idxBigJump = np.where((y_prob[1:] - y_prob[0:-1]) > 0.1)[0] + 1\n",
    "\n",
    "        ylim = plt.ylim()\n",
    "\n",
    "        for i, val in enumerate(idxBigJump):\n",
    "            #print(i, val)\n",
    "            X_big = X_curr[val,:]\n",
    "            X_sml = X_curr[val-1,:]\n",
    "\n",
    "            idxDiff = np.where(abs(X_big - X_sml) > 1e-4)[0]\n",
    "\n",
    "            # now look for *big* differences\n",
    "\n",
    "            # get anchors for plot locations\n",
    "            anchor_x = t[val]\n",
    "            anchor_y = ylim[1]-0.1*(ylim[1]-ylim[0]) # the higher prob\n",
    "\n",
    "            currVal = 0\n",
    "            for m, mval in enumerate(idxDiff):\n",
    "                if X_big[mval] > X_sml[mval]:\n",
    "                    txt_for_plot = '^   ' + X_header[mval]\n",
    "                else:\n",
    "                    txt_for_plot = ' v  ' + X_header[mval]\n",
    "\n",
    "                # the if statement tries to throttle overlapping labels\n",
    "                if mval > (currVal+4):\n",
    "                    plt.plot([anchor_x, anchor_x], [0.0,0.9], '--', color='k', linewidth=2)\n",
    "                    plt.text(anchor_x+1,anchor_y-(m*0.02),txt_for_plot,fontsize=14)\n",
    "                    currVal = mval\n",
    "    \n",
    "    plt.title(str(iid) + ', hospital expiry = ' + hosp_exp,fontsize=14)\n",
    "    fig.set_size_inches(10, 6)\n",
    "    fig.savefig('./plots/' + str(iid) + '.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(X_curr,columns=X_header).to_csv('tmpdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that, given two times, calculates:\n",
    "#  - the top 3 features which resulted in a lower risk\n",
    "#  - the top 3 features which resulted in a higher risk\n",
    "\n",
    "# what changed to cause these large spikes?\n",
    "idxBigJump = np.where((y_prob[1:] - y_prob[0:-1]) > 0.1)[0] + 1\n",
    "\n",
    "t1 = idxBigJump[0]-1\n",
    "t2 = idxBigJump[0]\n",
    "\n",
    "# bonus points for some estimate of the increased risk\n",
    "def features_changing_risk(X, mdl, t1=0, t2=1):\n",
    "    X1 = np.reshape(X[t1,:],[1,X.shape[1]])\n",
    "    X2 = np.reshape(X[t2,:],[1,X.shape[1]])\n",
    "    \n",
    "    #print(X1)\n",
    "    #print(X2)\n",
    "    y1 = mdl.predict_proba(X1)[0,1]\n",
    "    y2 = mdl.predict_proba(X2)[0,1]\n",
    "    print('Pred1: {:0.4f}. Pred2: {:0.4f}.'.format(y1,y2))\n",
    "    \n",
    "    # look for any difference\n",
    "    idxDiff = np.where(abs(X2 - X1) > 1e-4)[1]\n",
    "    \n",
    "    # now loop through and look for *big* differences\n",
    "    diffMagnitude = np.zeros(idxDiff.shape)\n",
    "    for m, mval in enumerate(idxDiff):\n",
    "        X_tmp = np.copy(X1)\n",
    "        X_tmp[0,mval] = X2[0,mval]\n",
    "        \n",
    "        y_eval = mdl.predict_proba(X_tmp)\n",
    "        y_eval = y_eval[0,1]\n",
    "        \n",
    "        y_diff = y_eval-y1\n",
    "        y_diff_pct = (y_eval-y1) / abs(y2-y1) * 100.0\n",
    "        \n",
    "        diffMagnitude[m] = y_diff_pct\n",
    "        print('{:3g} of {:3g} - idx={:3g}'.format(m, len(idxDiff), mval),\n",
    "              '{:20s} - {:0.4f} vs. {:0.4f}'.format(X_header[mval], y_eval, y1),\n",
    "              '\\t{:1.4f}, {:2.1f}% of the overall change'.format(y_diff, y_diff_pct))\n",
    "        \n",
    "    \n",
    "    sort_indices = np.argsort(diffMagnitude)\n",
    "    idxDiff = idxDiff[sort_indices]\n",
    "    if len(idxDiff)<3:\n",
    "        idxDiff = [idxDiff, np.nan, np.nan]\n",
    "    \n",
    "    return idxDiff[0:3]\n",
    "\n",
    "idxIncreased = features_changing_risk(X_curr, xgb_model, t1=t1, t2=t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that, given two times, calculates:\n",
    "#  - the top 3 features which resulted in a lower risk\n",
    "#  - the top 3 features which resulted in a higher risk\n",
    "\n",
    "# what changed to cause these large spikes?\n",
    "idxBigJump = np.where((y_prob[1:] - y_prob[0:-1]) > 0.1)[0] + 1\n",
    "\n",
    "t1 = idxBigJump[0]-1\n",
    "t2 = idxBigJump[0]\n",
    "\n",
    "# bonus points for some estimate of the increased risk\n",
    "def feature_importance(X, mdl, t1=0, t2=1):\n",
    "    X1 = np.reshape(X[t1,:],[1,X.shape[1]])\n",
    "    X2 = np.reshape(X[t2,:],[1,X.shape[1]])\n",
    "    \n",
    "    #print(X1)\n",
    "    #print(X2)\n",
    "    y1 = mdl.predict_proba(X1)[0,1]\n",
    "    y2 = mdl.predict_proba(X2)[0,1]\n",
    "    print('Pred1: {:0.4f}. Pred2: {:0.4f}.'.format(y1,y2))\n",
    "    \n",
    "    # look for any difference\n",
    "    idxDiff = np.where(abs(X2 - X1) > 1e-4)[1]\n",
    "    \n",
    "    # now loop through and look for *big* differences\n",
    "    diffMagnitude = np.zeros(idxDiff.shape)\n",
    "    for m, mval in enumerate(idxDiff):\n",
    "        X_tmp = np.copy(X2)\n",
    "        X_tmp[0,mval] = X1[0,mval]\n",
    "        \n",
    "        y_eval = mdl.predict_proba(X_tmp)\n",
    "        y_eval = y_eval[0,1]\n",
    "        \n",
    "        y_diff = y_eval-y1\n",
    "        y_diff_pct = (y2-y_eval) / abs(y2-y1) * 100.0\n",
    "        \n",
    "        diffMagnitude[m] = y_diff_pct\n",
    "        print('{:3g} of {:3g} - idx={:3g}'.format(m, len(idxDiff), mval),\n",
    "              '{:20s} - {:0.4f} vs. {:0.4f}'.format(X_header[mval], y_eval, y1),\n",
    "              '\\t{:1.4f}, {:2.1f}% of the overall change'.format(y_diff, y_diff_pct))\n",
    "        \n",
    "    \n",
    "    sort_indices = np.argsort(diffMagnitude)\n",
    "    idxDiff = idxDiff[sort_indices]\n",
    "    if len(idxDiff)<3:\n",
    "        idxDiff = [idxDiff, np.nan, np.nan]\n",
    "    \n",
    "    return idxDiff[0:3]\n",
    "\n",
    "idxIncreased = feature_importance(X_curr, xgb_model, t1=t1, t2=t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem with the above is it's all univariate.. so if we remove/add a single feature, it's not really representative of the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a single individual's data from saved csv files (for convenience)\n",
    "iid = 207012 # 203461, 207012\n",
    "df_curr = pd.read_csv('./data/' + str(iid) + '.csv')\n",
    "df_curr['charttime'] = pd.to_datetime(df_curr['charttime'])\n",
    "\n",
    "# change charttime into time elapsed\n",
    "df_curr['timeelapsed'] = (df_curr['charttime'] - df_static.loc[iid,'intime']) / np.timedelta64(1, 'm')\n",
    "df_curr.set_index('timeelapsed',inplace=True)\n",
    "df_curr.head()\n",
    "\n",
    "# this can take ~10-30 seconds to generate the features for all the rows\n",
    "df_x = mp.extract_feature_across_sp(df_curr)\n",
    "X_curr = df_x.values.astype(float)\n",
    "\n",
    "# add in the static variables\n",
    "X_static = np.tile(df_static.loc[iid,vars_static].values, [X_curr.shape[0],1]).astype(float)\n",
    "X_curr = np.column_stack([X_curr, X_static])\n",
    "\n",
    "# create the outcome\n",
    "y_curr = np.tile( co.loc[iid,'hospital_expire_flag'], [X_curr.shape[0],] )\n",
    "\n",
    "# generate probability for the window selected for this patient\n",
    "y_prob = xgb_model.predict_proba(X_curr)\n",
    "y_prob = y_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot this probability over time\n",
    "t = df_x.index.values # convert to hours\n",
    "\n",
    "plt.figure(figsize=[9,9])\n",
    "plt.plot(t,y_prob,'-',color=col[0],linewidth=2)\n",
    "\n",
    "plt.xlabel('Time (hours)',fontsize=16)\n",
    "plt.ylabel('Risk',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.iloc[145:165].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prints out three random test cases which we have .csv files for\n",
    "# we only saved csv files for ICUSTAY_ID < 210000, to save space\n",
    "iid_test[iid_test < 210000][40:80]\n",
    "# 202887, 207046, 200806, 205803, 201975, 209108 are metavision patients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
